{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74243cc-ff12-4851-83ba-f79b1ec0fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from scipy.ndimage import generic_filter\n",
    "from mintpy.utils import readfile as timeseries_readfile\n",
    "\n",
    "# Standardized Thresholds\n",
    "T_COH_THRESH = 0.85\n",
    "S_COH_THRESH = 0.85\n",
    "V_STD_THRESH = 2.0\n",
    "NEIGHBORHOOD_SIZE = 10      \n",
    "STABILITY_DENSITY = 0.8    \n",
    "WINDOW_SIZE = 10           \n",
    "\n",
    "def create_master_reference(vel_file='velocity.h5', t_coh_file='temporalCoherence.h5', s_coh_file='avgSpatialCoh.h5'):\n",
    "   \n",
    "    #Load Data\n",
    "    v_std, meta = timeseries_readfile.read(vel_file, datasetName='velocityStd')\n",
    "    t_coh, _ = timeseries_readfile.read(t_coh_file, datasetName='temporalCoherence')\n",
    "    s_coh, _ = timeseries_readfile.read(s_coh_file, datasetName='coherence')\n",
    "    img_height, img_width = v_std.shape\n",
    "\n",
    "    # Apply the Filter\n",
    "    stable_mask = (t_coh >= T_COH_THRESH) & (s_coh >= S_COH_THRESH) & (v_std <= V_STD_THRESH)\n",
    "    \n",
    "    # Spatial Density Filtering \n",
    "    def count_stable(window): return np.sum(window)\n",
    "    stable_neighbor_count = generic_filter(stable_mask.astype(int), count_stable, size=NEIGHBORHOOD_SIZE)\n",
    "    min_neighbors = int(STABILITY_DENSITY * (NEIGHBORHOOD_SIZE**2))\n",
    "    cluster_mask = (stable_mask == 1) & (stable_neighbor_count >= min_neighbors)\n",
    "    \n",
    "    # Targeted Weighting \n",
    "    masked_vstd = np.where(cluster_mask == 1, v_std, np.nan) # Ignore anything outside our stable clusters\n",
    "    if np.all(np.isnan(masked_vstd)):\n",
    "        print(\"Error: No stable clusters found. Lower your thresholds.\")\n",
    "        return\n",
    "\n",
    "    # Find the absolute best pixel (Lowest StdDev) within a cluster\n",
    "    min_idx = np.nanargmin(masked_vstd)\n",
    "    center_y, center_x = np.unravel_index(min_idx, v_std.shape)\n",
    "    \n",
    "    print(f\"Optimal Reference Seed: Y={center_y}, X={center_x} (StdDev: {v_std[center_y, center_x]:.4f} mm/yr)\")\n",
    "\n",
    "    # Define the local weighting window\n",
    "    half_w = WINDOW_SIZE // 2\n",
    "    y_min, y_max = max(0, center_y - half_w), min(img_height, center_y + half_w)\n",
    "    x_min, x_max = max(0, center_x - half_w), min(img_width, center_x + half_w)\n",
    "\n",
    "    # Calculate Inverse Variance Weights\n",
    "    final_weights = np.zeros_like(v_std, dtype=np.float32)\n",
    "    target_zone_vstd = v_std[y_min:y_max, x_min:x_max]\n",
    "    weights_subset = 1.0 / (target_zone_vstd**2 + 1e-6)\n",
    "    \n",
    "    # Normalize\n",
    "    weights_subset /= np.max(weights_subset)\n",
    "    final_weights[y_min:y_max, x_min:x_max] = weights_subset\n",
    "\n",
    "    # 4. Save the Mask File\n",
    "    output_name = 'A_Master_Reference_Weights.h5'\n",
    "    with h5py.File(output_name, 'w') as f:\n",
    "        f.create_dataset('mask', data=final_weights)\n",
    "        for k, v in meta.items():\n",
    "            f.attrs[k] = v\n",
    "            \n",
    "    print(f\"Success! Master reference file saved as: {output_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_master_reference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landsus",
   "language": "python",
   "name": "landsus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
